Deep Learning For Beginners

This is a repository of notes and concepts from the Udacity Bertelsmann 2019 AI challenge course. This repository extracts the most basic concepts related to deep learning.



## Introduction To NeUral Networks

- Models

- Supervised Learning

- Linear Function

- Perceptrons

- Logic Gates

- AND Gate

- OR Gate

- NOT Gate 

- NAND Gate

  - [Neural Representation of AND, OR, NOT, XOR and XNOR Logic Gates Perceptron Algorithm](https://medium.com/@stanleydukor/neural-representation-of-and-or-not-xor-and-xnor-logic-gates-perceptron-algorithm-b0275375fea1)

    

- Summation 

- Sigmoid 

- Discrete vs Continous

- Differentiation

- Loss Function

- Log Loss Function

- Gradient Descent

- Continuous Error Functions

- Discrete Predictions

- Continuous Predictions

- Step Function

- Activation Functions

- Sigmoid Function

- Probability Space

- Classification Problem 

- Exponential function

  - [What is e?](https://www.nde-ed.org/EducationResources/Math/Math-e.php)

- Softmax Function

- One Hot Encoding 

- Maximum Likelihood

- Joint probability

- Independent Probability

- Maximum Likelihood Estimation

- Logarithm

- Cross Entropy
